# ğŸ—ï¸ Project Oracle - Architecture Overview

**Complete System Architecture Documentation**

---

## ğŸ¯ Design Principles

Project Oracle was designed with these core principles:

1. **Cost-Effective** - Minimize API costs through smart caching and deduplication
2. **Autonomous** - Work seamlessly with AI agents without human intervention
3. **Incremental** - Only process changed content, not entire corpus
4. **Scalable** - Handle growing documentation without performance degradation
5. **Secure** - Protect sensitive keys, implement proper access control

---

## ğŸ“ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER / AI AGENT                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                         â”‚
                 â”‚ Trigger Reindex         â”‚ Search Query
                 â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GitHub Actions           â”‚  â”‚   Query CLI              â”‚
â”‚   Workflow                 â”‚  â”‚   (Local/Server)         â”‚
â”‚                            â”‚  â”‚                          â”‚
â”‚ 1. Checkout repo           â”‚  â”‚ 1. Parse query           â”‚
â”‚ 2. Setup Node.js           â”‚  â”‚ 2. Generate embedding    â”‚
â”‚ 3. Install deps            â”‚  â”‚ 3. Call RPC              â”‚
â”‚ 4. Run indexer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  â”‚ 4. Format results        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                             â”‚
             â”‚ Index Updates               â”‚ Search Request
             â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SUPABASE (PostgreSQL + pgvector)            â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ knowledge_chunks  â”‚      â”‚ RPCs & Functions    â”‚     â”‚
â”‚  â”‚                   â”‚      â”‚                     â”‚     â”‚
â”‚  â”‚ â€¢ id (uuid)       â”‚      â”‚ â€¢ match_knowledge   â”‚     â”‚
â”‚  â”‚ â€¢ file_path       â”‚      â”‚   _chunks()         â”‚     â”‚
â”‚  â”‚ â€¢ breadcrumb      â”‚      â”‚ â€¢ delete_chunks     â”‚     â”‚
â”‚  â”‚ â€¢ content         â”‚      â”‚   _by_file()        â”‚     â”‚
â”‚  â”‚ â€¢ content_hash    â”‚      â”‚                     â”‚     â”‚
â”‚  â”‚ â€¢ embedding       â”‚â—„â”€â”€â”€â”€â”€â”¤                     â”‚     â”‚
â”‚  â”‚   VECTOR(1536)    â”‚      â”‚                     â”‚     â”‚
â”‚  â”‚ â€¢ metadata        â”‚      â”‚                     â”‚     â”‚
â”‚  â”‚ â€¢ timestamps      â”‚      â”‚                     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                          â”‚
â”‚  Indexes:                                                â”‚
â”‚  â€¢ IVFFlat on embedding (cosine similarity)              â”‚
â”‚  â€¢ B-tree on file_path, content_hash, created_at         â”‚
â”‚                                                          â”‚
â”‚  RLS Policies:                                           â”‚
â”‚  â€¢ READ: authenticated users                             â”‚
â”‚  â€¢ WRITE: service_role only                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–²
                             â”‚
                             â”‚ Embeddings API
                             â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   OpenAI API         â”‚
                  â”‚                      â”‚
                  â”‚ text-embedding-      â”‚
                  â”‚ 3-small              â”‚
                  â”‚                      â”‚
                  â”‚ Input: Text          â”‚
                  â”‚ Output: [1536]float  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Indexing Pipeline

### **Phase 1: Discovery**
```typescript
// Scan filesystem for markdown files
const patterns = [
  'docs/**/*.md',
  'README.md',
  'AI_CODING_INSTRUCTIONS.md',
  '.agent/workflows/*.md',
  '**/README.md'
];

const files = await glob(patterns);
// Result: ['docs/strategy/AGENTS.md', 'README.md', ...]
```

**Output**: List of file paths to process

---

### **Phase 2: Text Splitting**
```typescript
// Hierarchy-aware Markdown splitting
const splitter = RecursiveCharacterTextSplitter.fromLanguage('markdown', {
  chunkSize: 1000,      // Target chunk size
  chunkOverlap: 200,    // Overlap between chunks
});

const chunks = await splitter.splitText(fileContent);
```

**Key Features**:
- Respects Markdown structure (headings, code blocks)
- Maintains context with overlap
- Builds hierarchical breadcrumbs

**Example Breadcrumb**:
```
docs/strategy/AGENTS.md > Phase 1: Planning > Expert Consultation
```

---

### **Phase 3: Change Detection**
```typescript
// SHA256 hashing for deduplication
const contentHash = crypto
  .createHash('sha256')
  .update(chunkContent, 'utf8')
  .digest('hex');

// Check if chunk exists with same hash
const existing = await supabase
  .from('knowledge_chunks')
  .select('id')
  .eq('file_path', filePath)
  .eq('content_hash', contentHash);

if (existing.data?.length > 0) {
  // Skip - content unchanged
  continue;
}
```

**Why SHA256?**
- Deterministic: Same content = same hash
- Fast: O(n) complexity
- Collision-resistant: Virtually impossible for docs

---

### **Phase 4: Embedding Generation**
```typescript
// OpenAI API call with rate limiting
const limit = pLimit(10); // 10 concurrent requests

const embeddings = await Promise.all(
  chunks.map((chunk) =>
    limit(async () => {
      const response = await openai.embeddings.create({
        model: 'text-embedding-3-small',
        input: chunk.content,
        encoding_format: 'float',
      });
      return response.data[0].embedding; // [1536] floats
    })
  )
);
```

**Rate Limiting**:
- Prevents API throttling
- Configurable concurrency (default: 10)
- Automatic retries with exponential backoff

---

### **Phase 5: Database Upsert**
```typescript
// Insert or update chunks
const { error } = await supabase
  .from('knowledge_chunks')
  .upsert(rows, {
    onConflict: 'file_path,content_hash',
  });

// Delete orphaned chunks (removed from file)
await supabase.rpc('delete_chunks_by_file', {
  target_file_path: filePath,
  keep_hashes: currentHashes,
});
```

**Atomic Operations**:
- Upsert: Prevents duplicates
- Delete: Cleans up orphans
- Transaction: All-or-nothing

---

## ğŸ” Query Pipeline

### **Phase 1: Query Embedding**
```typescript
// Convert natural language to vector
const { embedding } = await generateEmbedding(userQuery);
// Input: "How does offline sync work?"
// Output: [1536] floats
```

---

### **Phase 2: Vector Similarity Search**
```sql
-- RPC: match_knowledge_chunks
SELECT
  id,
  file_path,
  breadcrumb,
  content,
  1 - (embedding <=> query_embedding) AS similarity
FROM knowledge_chunks
WHERE 1 - (embedding <=> query_embedding) > match_threshold
ORDER BY embedding <=> query_embedding
LIMIT match_count;
```

**Similarity Metric**: Cosine similarity (1 - cosine distance)
- 1.0 = Identical
- 0.7+ = Highly relevant
- 0.5+ = Somewhat relevant
- < 0.5 = Not relevant

---

### **Phase 3: Result Formatting**
```typescript
// Format and display results
results.forEach((result, index) => {
  console.log(`ğŸ“„ Result ${index + 1}: ${result.breadcrumb}`);
  console.log(`   Similarity: ${(result.similarity * 100).toFixed(1)}%`);
  console.log(`   Preview: ${result.content.substring(0, 300)}...`);
});
```

---

## ğŸ—„ï¸ Database Schema

### **Table: knowledge_chunks**

```sql
CREATE TABLE knowledge_chunks (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  
  -- File identification
  file_path TEXT NOT NULL,
  breadcrumb TEXT,
  
  -- Content
  content TEXT NOT NULL,
  content_hash TEXT NOT NULL,
  
  -- Vector representation
  embedding VECTOR(1536) NOT NULL,
  
  -- Extensible metadata
  metadata JSONB DEFAULT '{}'::jsonb,
  
  -- Timestamps
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),
  
  -- Constraints
  CONSTRAINT unique_file_hash UNIQUE (file_path, content_hash)
);
```

### **Indexes**

```sql
-- Vector similarity search (IVFFlat)
CREATE INDEX knowledge_chunks_embedding_idx 
  ON knowledge_chunks 
  USING ivfflat (embedding vector_cosine_ops)
  WITH (lists = 100);

-- File path lookups
CREATE INDEX knowledge_chunks_file_path_idx 
  ON knowledge_chunks (file_path);

-- Hash lookups for change detection
CREATE INDEX knowledge_chunks_content_hash_idx 
  ON knowledge_chunks (content_hash);

-- Timestamp filtering
CREATE INDEX knowledge_chunks_created_at_idx 
  ON knowledge_chunks (created_at DESC);
```

**IVFFlat Index**:
- `lists = 100`: Optimal for 730-10,000 chunks
- `vector_cosine_ops`: Optimized for cosine similarity
- Trade-off: ~95% recall for 10x speed improvement

---

### **RPCs**

#### **match_knowledge_chunks**
```sql
CREATE OR REPLACE FUNCTION match_knowledge_chunks(
  query_embedding VECTOR(1536),
  match_threshold FLOAT DEFAULT 0.5,
  match_count INT DEFAULT 5
)
RETURNS TABLE (
  id UUID,
  file_path TEXT,
  breadcrumb TEXT,
  content TEXT,
  similarity FLOAT
) AS $$
BEGIN
  RETURN QUERY
  SELECT
    kc.id,
    kc.file_path,
    kc.breadcrumb,
    kc.content,
    1 - (kc.embedding <=> query_embedding) AS similarity
  FROM knowledge_chunks kc
  WHERE 1 - (kc.embedding <=> query_embedding) > match_threshold
  ORDER BY kc.embedding <=> query_embedding
  LIMIT match_count;
END;
$$ LANGUAGE plpgsql;
```

#### **delete_chunks_by_file**
```sql
CREATE OR REPLACE FUNCTION delete_chunks_by_file(
  target_file_path TEXT,
  keep_hashes TEXT[]
)
RETURNS VOID AS $$
BEGIN
  DELETE FROM knowledge_chunks
  WHERE file_path = target_file_path
    AND content_hash != ALL(keep_hashes);
END;
$$ LANGUAGE plpgsql;
```

---

## ğŸ”’ Security Architecture

### **Row-Level Security (RLS)**

```sql
-- Enable RLS
ALTER TABLE knowledge_chunks ENABLE ROW LEVEL SECURITY;

-- Read policy (authenticated users)
CREATE POLICY "Allow authenticated users to read knowledge chunks"
  ON knowledge_chunks
  FOR SELECT
  TO authenticated
  USING (true);

-- Write policy (service role only - implicit)
-- No explicit policy needed - defaults to denying non-service-role writes
```

### **Key Management**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Secret Management Strategy                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Local Development:
  .env file (git-ignored)
  â”œâ”€â”€ SUPABASE_URL
  â”œâ”€â”€ SUPABASE_SERVICE_ROLE_KEY
  â””â”€â”€ OPENAI_API_KEY

CI/CD (GitHub Actions):
  Repository Secrets
  â”œâ”€â”€ SUPABASE_URL
  â”œâ”€â”€ SUPABASE_SERVICE_ROLE_KEY
  â””â”€â”€ OPENAI_API_KEY

Never Exposed To:
  âŒ Client-side code
  âŒ Git repository
  âŒ Public logs
  âŒ Unauthenticated endpoints
```

---

## ğŸ“Š Performance Characteristics

### **Scalability**

| Chunk Count | Index Type | Search Time | Build Time |
|-------------|-----------|-------------|------------|
| 100-1,000 | IVFFlat | ~30ms | ~5s |
| 1,000-10,000 | IVFFlat | ~50ms | ~30s |
| 10,000-100,000 | IVFFlat | ~100ms | ~3min |
| 100,000+ | HNSW | ~20ms | ~15min |

**Current Scale**: 730 chunks â†’ ~30-50ms search time

### **Cost Optimization Strategies**

1. **Hash-Based Deduplication**
   - Avoids re-embedding unchanged content
   - Savings: ~95% on incremental updates

2. **Rate Limiting**
   - Prevents API throttling
   - Stays within free tier limits

3. **Manual Trigger**
   - Only runs when explicitly needed
   - Avoids wasteful auto-indexing

4. **Batch Processing**
   - Processes 10 chunks concurrently
   - Optimal throughput vs. rate limits

---

## ğŸ”„ Data Flow Diagrams

### **Indexing Flow**

```
File System                  Indexer                    OpenAI API           Supabase
    â”‚                           â”‚                             â”‚                  â”‚
    â”‚  Read .md files           â”‚                             â”‚                  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                             â”‚                  â”‚
    â”‚                           â”‚                             â”‚                  â”‚
    â”‚                           â”‚  Split into chunks          â”‚                  â”‚
    â”‚                           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚                  â”‚
    â”‚                           â”‚         â”‚                   â”‚                  â”‚
    â”‚                           â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚                  â”‚
    â”‚                           â”‚                             â”‚                  â”‚
    â”‚                           â”‚  Generate SHA256 hashes     â”‚                  â”‚
    â”‚                           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚                  â”‚
    â”‚                           â”‚         â”‚                   â”‚                  â”‚
    â”‚                           â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚                  â”‚
    â”‚                           â”‚                             â”‚                  â”‚
    â”‚                           â”‚  Query existing hashes      â”‚                  â”‚
    â”‚                           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
    â”‚                           â”‚                             â”‚                  â”‚
    â”‚                           â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                           â”‚  (list of existing hashes)  â”‚                  â”‚
    â”‚                           â”‚                             â”‚                  â”‚
    â”‚                           â”‚  Filter changed chunks      â”‚                  â”‚
    â”‚                           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚                  â”‚
    â”‚                           â”‚         â”‚                   â”‚                  â”‚
    â”‚                           â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚                  â”‚
    â”‚                           â”‚                             â”‚                  â”‚
    â”‚                           â”‚  Generate embeddings        â”‚                  â”‚
    â”‚                           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                  â”‚
    â”‚                           â”‚                             â”‚                  â”‚
    â”‚                           â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚
    â”‚                           â”‚  (1536-dim vectors)         â”‚                  â”‚
    â”‚                           â”‚                             â”‚                  â”‚
    â”‚                           â”‚  Upsert chunks                                â”‚
    â”‚                           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
    â”‚                           â”‚                             â”‚                  â”‚
    â”‚                           â”‚  Delete orphaned chunks                        â”‚
    â”‚                           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
    â”‚                           â”‚                             â”‚                  â”‚
    â”‚                           â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                           â”‚  (success confirmation)     â”‚                  â”‚
```

### **Query Flow**

```
CLI User                 Query Script              OpenAI API           Supabase
   â”‚                          â”‚                          â”‚                  â”‚
   â”‚  "How does X work?"      â”‚                          â”‚                  â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                          â”‚                  â”‚
   â”‚                          â”‚                          â”‚                  â”‚
   â”‚                          â”‚  Generate embedding      â”‚                  â”‚
   â”‚                          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                  â”‚
   â”‚                          â”‚                          â”‚                  â”‚
   â”‚                          â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚
   â”‚                          â”‚  (1536-dim vector)       â”‚                  â”‚
   â”‚                          â”‚                          â”‚                  â”‚
   â”‚                          â”‚  Call match_knowledge_chunks RPC            â”‚
   â”‚                          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
   â”‚                          â”‚  {                       â”‚                  â”‚
   â”‚                          â”‚    query_embedding,      â”‚                  â”‚
   â”‚                          â”‚    match_threshold: 0.5, â”‚                  â”‚
   â”‚                          â”‚    match_count: 5        â”‚                  â”‚
   â”‚                          â”‚  }                       â”‚                  â”‚
   â”‚                          â”‚                          â”‚                  â”‚
   â”‚                          â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚                          â”‚  (top 5 results)         â”‚                  â”‚
   â”‚                          â”‚                          â”‚                  â”‚
   â”‚                          â”‚  Format results          â”‚                  â”‚
   â”‚                          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚                  â”‚
   â”‚                          â”‚         â”‚                â”‚                  â”‚
   â”‚                          â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚                  â”‚
   â”‚                          â”‚                          â”‚                  â”‚
   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                          â”‚                  â”‚
   â”‚  (formatted output)      â”‚                          â”‚                  â”‚
```

---

## ğŸš€ Deployment Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         GitHub                                  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Code Repository â”‚         â”‚   GitHub Actions        â”‚      â”‚
â”‚  â”‚                  â”‚         â”‚                         â”‚      â”‚
â”‚  â”‚  â€¢ Docs (.md)    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Manual Trigger         â”‚      â”‚
â”‚  â”‚  â€¢ Scripts       â”‚         â”‚  (workflow_dispatch)    â”‚      â”‚
â”‚  â”‚  â€¢ Migrations    â”‚         â”‚                         â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  Steps:                 â”‚      â”‚
â”‚                               â”‚  1. Checkout            â”‚      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  2. Setup Node.js       â”‚      â”‚
â”‚  â”‚  Secrets         â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  3. Install deps        â”‚      â”‚
â”‚  â”‚                  â”‚         â”‚  4. Run indexer â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”
â”‚  â”‚  â€¢ SUPABASE_URL  â”‚         â”‚  5. Report results      â”‚      â”‚   â”‚
â”‚  â”‚  â€¢ SERVICE_KEY   â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚
â”‚  â”‚  â€¢ OPENAI_KEY    â”‚                                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                                                                     â”‚
                                                                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                         Supabase Cloud                          â”‚  â”‚
â”‚                                                                 â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚             PostgreSQL + pgvector                        â”‚   â”‚  â”‚
â”‚  â”‚                                                          â”‚   â”‚  â”‚
â”‚  â”‚  knowledge_chunks table                                  â”‚â—„â”€â”€â”¼â”€â”€â”˜
â”‚  â”‚  â€¢ 730+ chunks                                           â”‚   â”‚
â”‚  â”‚  â€¢ 1536-dim vectors                                      â”‚   â”‚
â”‚  â”‚  â€¢ IVFFlat index                                         â”‚   â”‚
â”‚  â”‚  â€¢ RLS policies                                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â–²
                                    â”‚
                                    â”‚ Search Queries
                                    â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚  Local CLI     â”‚
                            â”‚  or           â”‚
                            â”‚  Future API    â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”® Future Enhancements

### **Phase 2: Advanced Search**
- Hybrid search (vector + full-text)
- Reranking with cross-encoder models
- Query expansion and synonyms
- Filters (file type, date range, etc.)

### **Phase 3: UI Integration**
- Web-based search interface
- VS Code extension
- Slack bot integration
- API endpoint for external tools

### **Phase 4: Intelligence**
- Automatic query suggestions
- Related document recommendations
- Usage analytics and insights
- Quality scoring for chunks

### **Phase 5: Multi-Modal**
- Image/diagram indexing
- Code snippet search
- Mermaid diagram parsing
- Video transcript search

---

## ğŸ“š References

- **pgvector Documentation**: https://github.com/pgvector/pgvector
- **OpenAI Embeddings**: https://platform.openai.com/docs/guides/embeddings
- **LangChain Text Splitters**: https://js.langchain.com/docs/modules/data_connection/document_transformers/
- **GitHub Actions**: https://docs.github.com/en/actions

---

**Last Updated**: 2026-02-04  
**Maintained By**: Questerix Development Team
